# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MW7XbRZ7ideRFkkEcmY_oSskOjdnMLLm
"""

import streamlit as st
import joblib
from gensim.models import Word2Vec
import numpy as np
import PyPDF2
import os
from nltk.tokenize import word_tokenize
from unidecode import unidecode

# Configuraci√≥n
st.set_page_config(page_title="Requisitos Contractuales", layout="wide")
st.title("üìÑ Detecci√≥n Autom√°tica de Requisitos Contractuales en Minutas")

# Cargar vectorizadores
vectorizador_tfidf = joblib.load("vectorizador_tfidf.pkl")
modelo_w2v = Word2Vec.load("word2vec_global.model")

# Mapas de modelos por etiqueta
etiquetas_tfidf = ["Retenci√≥n en garant√≠a", "Gastos reembolsables", "Cl√°usula de Cesi√≥n", "Socializaci√≥n", "Subcontrataci√≥n","Uso de opci√≥n", "Reajuste salarial",  "GAB-F-213", "GAB-F-214", "GAB-F-221", "Reuni√≥n de inicio"]
etiquetas_w2v = ["GAB-F-105","Garant√≠as y seguros","Reajuste de tarifas y precios" ]

# Funciones auxiliares
def extraer_texto_pdf(uploaded_file):
    reader = PyPDF2.PdfReader(uploaded_file)
    texto = ""
    for page in reader.pages:
        texto += page.extract_text() + "\n"
    return texto

def preprocesar_texto(texto):
    texto = texto.lower()
    texto = unidecode(texto)
    texto = "".join([c for c in texto if c.isalnum() or c.isspace()])
    texto = " ".join(texto.split())
    return texto

def vector_promedio(doc, modelo, dimension=100):
    tokens = word_tokenize(doc)
    vectores = [modelo.wv[word] for word in tokens if word in modelo.wv]
    return np.mean(vectores, axis=0) if vectores else np.zeros(dimension)

# Subida de archivo
archivo = st.file_uploader("Adjunta una minuta en formato PDF", type=["pdf"])

if archivo:
    texto_original = extraer_texto_pdf(archivo)
    texto_proc = preprocesar_texto(texto_original)

    st.subheader("Texto Preprocesado")
    st.text_area("Contenido", texto_proc, height=200)

    resultados = {}

    # Clasificaci√≥n con TF-IDF
    X_tfidf = vectorizador_tfidf.transform([texto_proc])
    for etiqueta in etiquetas_tfidf:
        nombre_archivo = f"modelo_{unidecode(etiqueta.lower().replace(' ', '_'))}.pkl"
        modelo = joblib.load(os.path.join("modelos_finales", nombre_archivo))
        pred = modelo.predict(X_tfidf)[0]
        resultados[etiqueta] = "‚úÖ Identificado en el texto" if pred == 1 else "‚ùå No Identificado en el texto"

    # Clasificaci√≥n con Word2Vec
    X_w2v = vector_promedio(texto_proc, modelo_w2v, dimension=100).reshape(1, -1)
    for etiqueta in etiquetas_w2v:
        nombre_archivo = f"modelo_{unidecode(etiqueta.lower().replace(' ', '_'))}.pkl"
        modelo = joblib.load(os.path.join("modelos_finales", nombre_archivo))
        pred = modelo.predict(X_w2v)[0]
        resultados[etiqueta] = "‚úÖ Identificado en el texto" if pred == 1 else "‚ùå No Identificado en el texto"

    # Mostrar resultados
    st.subheader("üìå Resultados de Clasificaci√≥n")
    for etiqueta, resultado in resultados.items():
        st.markdown(f"**{etiqueta}:** {resultado}")